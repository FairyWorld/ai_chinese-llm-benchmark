## 目录
- [7月28~8月3](#7月288月3)
- [7月21~7月27](#7月217月27)
- [7月14~7月20](#7月147月20)
- [7月7~7月13](#7月77月13)
- [6月30~7月6](#6月307月6)
- [6月23~6月29](#6月236月29)
- [6月16~6月22](#6月166月22)
- [6月9~6月15](#6月96月15)
- [6月2~6月8](#6月26月8)
<br><br>

## 7月28~8月3
### 7月31日
- 【开源】阶跃星辰发布step-3模型，该模型拥有强大的视觉感知和复杂推理能力，可准确完成领域的复杂知识理解、数学与现实信息的交叉分析，以及日常生活中的各类视觉分析问题。详情见https://platform.stepfun.com/docs/llm/reasoning。
- 【闭源】谷歌发布Veo 3预览版模型，针对Veo 3预览版模型推出了图像转视频功能，并发布了Veo 3 Fast预览版模型，进一步提升生成效率。Veo 3详细请访问https://ai.google.dev/gemini-api/docs/video?hl=zh-cn&example=dialogue。

### 7月30日
- 【开源】腾讯发布端侧混合推理模型：Hunyuan-0.5B、Hunyuan-1.8B、Hunyuan-4B、Hunyuan-7B，这是腾讯开源的高效大语言模型系列，设计用于多样化计算环境的灵活部署，支持快慢思维双模式推理、256K超长上下文理解，采用分组查询注意力(GQA)机制实现高效推理。详情见https://modelscope.cn/models/Tencent-Hunyuan/Hunyuan-1.8B-Instruct

### 7月29日
- 【闭源】OpenAI推出ChatGPT Study Mode学习模式功能，这是一种新的学习体验，通过苏格拉底式提问引导理解、个性化响应和开放式反馈检查，帮助用户建立对任何主题的深入理解。目前面向Free、Plus、Pro和Teams用户开放。官方介绍：https://help.openai.com/en/articles/6825453-chatgpt-release-notes

### 7月28日
- 【闭源】阿里发布qwen-flash-2025-07-28、qwen3-coder-flash-2025-07-28
- 【闭源】阿里发布wan2.2-i2v-plus图生视频模型，相较2.1模型，新版本在画面细节表现和运动稳定性方面均有显著提升，生成速度提升达50%。详细信息，请访问https://help.aliyun.com/zh/model-studio/image-to-video-api-reference。
- 【闭源】阿里发布wan2.2-t2v-plus文生视频模型，新版本在画面细节表现和运动稳定性方面均有显著提升，生成速度提升达50%。详细信息见https://help.aliyun.com/zh/model-studio/text-to-video-api-reference。
- 【闭源】阿里发布wan2.2-t2i-flash、wan2.2-t2i-plus文生图模型，相较2.1模型，新版本在创意性、稳定性、写实质感上全面升级，生成速度提升达50%。详细请见https://help.aliyun.com/zh/model-studio/text-to-image-v2-api-reference。
- 【开源】智谱发布GLM-4.5系列模型，GLM-4.5拥有3550亿总参数和320亿激活参数，GLM-4.5-Air采用更紧凑设计，1060亿总参数和120亿激活参数。两个模型都是混合推理模型，提供复杂推理和工具使用的思维模式，以及即时响应的非思维模式。模型的相关详细介绍请见：https://docs.z.ai/guides/llm/glm-4.5

## 7月21~7月27
### 7月27日
- 【开源|多模态生成】腾讯发布HunyuanWorld-1.0，这是首个开源的沉浸式3D世界生成模型，支持从文字或图片生成可漫游、可交互的360度虚拟世界。如需了解更多信息，请访问https://3d-models.hunyuan.tencent.com/world/

### 7月25日
- 【闭源】科大讯飞发布星火X1的升级版本xunfei-spark-x1-0725，基于全国产算力训练的深度推理大模型，在数学运算、逻辑推理、幻觉治理等方面显著提升，支持130+语种，详细见官方介绍https://xinghuo.xfyun.cn/sparkapi。
- 【开源】阿里发布Qwen3-235B-A22B-Thinking-2507，是千问3-235B-A22B的思维增强版本，在逻辑推理、数学、科学、编码等推理任务上显著提升，支持256K长上下文理解。如需了解更多信息，请访问https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Thinking-2507/summary。

### 7月24日
- 【开源】无问芯穹发布Megrez2-3x7B-A3B-Preview，这是专为终端设备设计的MoE架构大模型，训练数据量5T Tokens，如需了解更多信息，请访问https://modelscope.cn/models/InfiniAI/Megrez2-3x7B-A3B-Preview/summary。
- 【开源】上海人工智能实验室发布开源多模态科学推理模型Intern-S1，基于235B MoE语言模型和6B视觉编码器构建，在5T多模态数据上预训练。如需了解更多信息，请访问https://modelscope.cn/models/Shanghai_AI_Laboratory/Intern-S1/summary。

### 7月23日
- 【闭源|多模态融合】商汤发布SenseNova-V6.5-Pro、SenseNova-V6.5-Turbo，这是日日新-融合模态模型的最新版本更新，专注于增强推理能力和提升训练效率。如需了解更多信息，请访问模型页面https://console.sensecore.cn/micro/help/docs/model-as-a-service/nova/model/fusionllm/FusionLLMs/。
- 【开源】阿里发布Qwen3-Coder-480B-A35B-Instruct，该模型在智能体编程、代理浏览器使用等基础编码任务上表现卓越，原生支持256K上下文并可扩展至1M，优化了对仓库规模的理解，支持Qwen Code、CLINE等多数平台的代理编码。如需了解更多信息，请访问https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct/summary。

### 7月22日
- 【开源】快手发布KAT-V1-40B，Kwaipilot-AutoThink 在LiveCodeBench Pro上所有开源模型中排名第一，这是一个专门设计以防止数据泄露的具有挑战性的基准测试，甚至超过了Seed和o3-mini等强大的专有系统。详细见https://modelscope.cn/models/Kwaipilot/KAT-V1-40B。
- 【闭源】谷歌发布gemini-2.5-flash-lite，这是Gemini 2.5系列的轻量版本，专注于速度快、成本低、性能高的平衡。如需了解更多有关Gemini 2.5 Flash-Lite的信息，请访问模型页面https://ai.google.dev/gemini-api/docs/models?hl=zh-cn#gemini-2.5-flash-lite。

### 7月21日
- 【开源】阿里发布Qwen3-235B-A22B-Instruct-2507，这是千问3非思考模式的更新版本，显著提升通用能力、逻辑推理和256K长文理解，在多语言知识覆盖范围大幅增加。如需了解更多信息，请访问https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Instruct-2507/summary。
<br><br>


## 7月14~7月20
### 7月17日
- 【闭源|多模态生成】谷歌发布veo-3.0-generate-preview，这是Veo的最新更新，引入了视频与音频生成功能。如需了解更多有关Veo 3的信息，请访问[模型页面](https://ai.google.dev/gemini-api/docs/models#veo-3)。
- 【闭源】谷歌提高了Imagen 4 Standard和Ultra的速率限制。更多详情请访问[速率限制页面](https://ai.google.dev/gemini-api/docs/rate-limits)。
- 【闭源】Anthropic已提高Claude Sonnet 4 的API速率限制，以便您能更从容地构建和扩展 Claude 相关应用。对于使用 1 - 4 级速率限制的客户，这些更改已立即适用于您的账户 —— 无需您采取任何操作。
- 【开源|多模态生成】HiDream-E1-1：智象未来HiDream团队在近期开源了最新迭代的图像编辑模型。支持动态分辨率，在图像质量和编辑精度方面相比上一代HiDream-E1-Full 有显著提升。[模型链接](https://www.modelscope.cn/models/HiDream-ai/HiDream-E1-1)。

### 7月16日
- 【闭源】腾讯发布turbos新版本hunyuan-turbos-20250716
- 【开源|多模态理解】Voxtral系列是Mistral AI近期发布的其首个开放式音频模型。 在 Mistral Small 3 的基础上增加了强大的音频理解能力。
  - 专用转录模式：可以在纯语音转录模式下运行，以最大化性能。默认情况下，Voxtral 会自动预测源音频的语言并相应地进行转录；
  - 长篇内容：具有 32k token的上下文长度，可处理长达 30 分钟的音频转录，或 40 分钟的理解；
  - 内置问答和摘要：支持直接通过音频提问。分析音频并生成结构化的摘要，无需单独的 ASR 和语言模型；
  - 多语言原生支持：自动语言检测和在全球最广泛使用的语言（英语、西班牙语、法语、葡萄牙语、印地语、德语、荷兰语、意大利语）中的领先性能；
  - 从语音直接调用函数：根据用户的语音意图直接触发后端功能、工作流或 API 调用；
  - 文本理解能力强：保留了其语言模型基础 Mistral Small 3.1 的文本理解能力。 
  - 模型链接：[Voxtral-Small-24B-2507](https://modelscope.cn/models/mistralai/Voxtral-Small-24B-2507)，[Voxtral-Mini-3B-2507](https://www.modelscope.cn/models/mistralai/Voxtral-Mini-3B-2507)

### 7月15日
  - 【闭源|多模态生成】智谱CogVideoX-3 视频生成模型上线新升级视频生成大模型，支持文生、图生视频，新增首尾帧生成功能，画面清晰度主观感受显著提升，主体大幅度运动自然流畅，还提升了高清现实及 3D 风格场景表现。详情见[CogVideoX-3](https://bigmodel.cn/dev/howuse/video-generation-model/CogVideoX-3)
  - 【闭源|文本】豆包发布doubao-seed-1-6-thinking-250715
  - 【闭源|文本】阿里发布qwen-turbo-2025-07-15

### 7月14日
  - 【闭源|文本】阿里发布qwen-plus-2025-07-14
  - 【闭源|向量模型】谷歌发布gemini-embedding-001，这是文本嵌入模型的稳定版本。如需了解更多，请参见[页面](https://ai.google.dev/gemini-api/docs/embeddings)。gemini-embedding-exp-03-07模型将于2025年8月14日停用。


<br><br>
## 7月7~7月13
### 7月11日
- 【开源|文本】Kimi K2：首个万亿级参数开源模型。月之暗面最新开源发布的一款具备更强代码能力、更擅长通用 Agent 任务的 MoE 架构基础模型，总参数 1T，激活参数 32B。在 SWE Bench Verified、Tau2、AceBench 等基准性能测试中，Kimi K2 均取得开源模型中的 SOTA 成绩，展现出在代码、Agent、数学推理任务上的领先能力。API价格：输入4元/百万token，输出16元/百万token。模型下载：[Kimi-K2-Instruct](https://www.modelscope.cn/models/moonshotai/Kimi-K2-Instruct)。技术博客：[Kimi-K2](https://moonshotai.github.io/Kimi-K2/)。
- 【开源|文本】Phi-4-mini-flash-reasoning：微软Phi-4 模型家族成员，一个基于合成数据构建的轻量级开放模型，专注于高质量、密集推理数据，并进一步微调以增强其高级数学推理能力，支持 64K token上下文长度。专为在内存/计算受限环境和延迟受限场景下的多步骤、逻辑密集型数学问题解决任务设计，擅长在需要深度分析思维的领域中跨步骤保持上下文、应用结构化逻辑并提供准确可靠的解决方案。模型下载：[Phi-4-mini-flash-reasoning](https://modelscope.cn/models/LLM-Research/Phi-4-mini-flash-reasoning)。
- 【闭源|文本】腾讯发布hunyuan-t1-20250711

### 7月10日
- 【闭源】Grok4：马斯克xAI发布号称宇宙最强的模型，打破多项纪录。在权威测试“Humanity’s Last Exam”（涵盖数学、科学及人文学科的 2500 道博士级难题）中，Grok 4 以 25.4% 正确率超越谷歌 Gemini 2.5 Pro（21.6%）和 OpenAI o3（21%）。马斯克称其“在所有学科表现优于博士水平”。单/多智能体协同：基础版为单智能体；Grok 4 Heavy 支持四智能体并行推理，通过协作提升复杂问题解决能力。订阅模式：标准版 30 美元/月，Grok 4 Heavy 版 300 美元/月（当前最贵 AI 订阅服务）。API价格：输入3美刀/百万token，输出15美刀/百万token。官方介绍：[grok-4](https://x.ai/news/grok-4)。[发布会链接](https://x.com/xai/status/1943158495588815072)。

### 7月9日
- 【开源】SmolLM3 ：由HuggingFace开源的一个 3B 参数的语言模型，旨在突破小型模型的界限。它支持双模式推理、6 种语言和长上下文，支持从64K扩展至128K的上下文处理，SmolLM3 是一个完全开放的模型，在 3B-4B 规模上提供了强大的性能。SmolLM3不仅公开了模型权重，还完整开源了训练数据混合、训练配置和代码。开发者可以通过Hugging Face的smollm存储库获取详细资料。
模型下载：[SmolLM3-3B](https://modelscope.cn/models/HuggingFaceTB/SmolLM3-3B)
- 【开源】Skywork-R1V3-38B：昆仑天工Skywork-R1V 系列中最新且最强大的开源多模态推理模型。基于 InternVL-38B 构建，它显著推动了多模态和跨学科智能的边界。主要通过后训练中的 RL 算法，R1V3 的推理能力得到了增强，在众多多模态推理基准测试中达到了开源的最先进（SOTA）性能。模型下载：[Skywork-R1V3-38B](https://modelscope.cn/models/Skywork/Skywork-R1V3-38B)

### 7月7日
- 【闭源】谷歌推出 Gemini API 批量模式。可将请求批量处理后异步发送。
<br><br>


## 6月30~7月6
### 7月3日
- 【闭源】Claude推出了搜索结果内容块的测试版，使 RAG 应用能够自然地进行引用。现在工具可以返回带有正确来源归属的搜索结果，并且 Claude 会自动在回复中引用这些来源，其引用质量与网络搜索相符。这消除了在自定义知识库应用中使用文档变通方法的需要。更多详情请参阅搜索结果文档。要启用此功能，请使用测试版标头 search-results-2025-06-09。

### 7月2日
- 【闭源】智谱发布GLM-4.1V-Thinking 系列视觉推理模型，GLM-4.1V-Thinking 系列是目前已知10B尺寸级别中性能最强的视觉推理模型。它在图表/视频理解、前端Coding、GUI任务等核心能力达到全面新SOTA，并引入思维链推理机制，显著提升模型在复杂场景中的回答精准度与可解释性。
- 【开源】智谱开源GLM-4.1V-9B-Thinking，基于 GLM-4-9B-0414 基座模型，推出新版VLM开源模型 GLM-4.1V-9B-Thinking ，引入思考范式，通过课程采样强化学习 RLCS（Reinforcement Learning with Curriculum Sampling）全面提升模型能力， 达到 10B 参数级别的视觉语言模型的最强性能，在18个榜单任务中持平甚至超过8倍参数量的 Qwen-2.5-VL-72B。 同步开源基座模型 GLM-4.1V-9B-Base，希望能够帮助更多研究者探索视觉语言模型的能力边界。模型下载：[GLM-4.1V-9B-Thinking](https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Thinking)。

### 7月1日
- 【开源】通义实验室开源ThinkSound: 多模态大型语言模型中的链式思维推理用于音频生成和编辑。尽管端到端的视频到音频生成已经取得了很大进步，但生成能够真实捕捉视觉内容微妙之处的高保真音频仍然具有挑战性。就像创意产业中的专业人士一样，这种生成需要对诸如视觉动态、声学环境和时间关系等项目进行复杂的推理。提出了 ThinkSound，这是一个新颖的框架，它利用链式思维（CoT）推理来实现逐步、交互式的音频生成和编辑。方法将过程分解为三个互补阶段：创建语义一致的声音景观的基础音效生成，通过精确的用户交互进行以对象为中心的细化，以及由自然语言指令引导的目标编辑。在每个阶段，多模态大型语言模型都会生成与上下文对齐的 CoT 推理，以指导统一的音频基础模型。此外，引入了 AudioCoT，这是一个带有结构化推理注释的综合数据集，建立了视觉内容、文本描述和声音合成之间的联系。实验表明，ThinkSound 在视频到音频生成方面达到了最先进的性能，无论是在音频指标还是 CoT 指标上，并且在分布外的电影生成音频基准测试中表现出色。[演示页面](https://ThinkSound-Project.github.io)，模型下载：[ThinkSound](https://modelscope.cn/models/iic/ThinkSound)。

### 6月30日
-【闭源】Claude宣布 Claude Opus 3 模型即将弃用。更多详情请参阅[文档](https://docs.anthropic.com/en/docs/about-claude/model-deprecations)。
<br><br>


## 6月23~6月29
### 6月29日
- 【闭源】ERNIE-4.5-Turbo-VL-Preview，图片理解、创作、翻译、代码等能力显著提升，支持128K上下文长度，首Token时延显著降低。
- 【闭源】百度文心小版本升级：ERNIE-4.5-Turbo-VL-Preview、ERNIE-4.5-Turbo-128K-Preview。
- 【开源】百度推出开源模型：ERNIE-4.5-0.3B、ERNIE-4.5-21B-A3B、多模态ERNIE-4.5-VL-28B-A3B、ERNIE-4.5-300B-A47B、多模态ERNIE-4.5-VL-424B-A47B，模型下载[ERNIE-4.5](https://modelscope.cn/collections/ERNIE-45-56f40e2777e348)。

### 6月27日
- 【开源】FLUX.1-Kontext-dev，FLUX.1 Kontext 是由 黑森林实验室（Black Forest Labs）开源的一款专业图像生成与编辑模型，专注于通过上下文感知技术实现精准的图像编辑。该模型支持文本和图像的混合输入，能够智能理解图像内容并执行对象修改、风格转换、背景替换等多种编辑任务，同时在多轮编辑中较好地保持主体一致性。其核心采用流匹配（Flow Matching）架构，结合双流与单流混合设计，提升了语义关联的精度和生成速度。Flux.1 Kontext [dev] 已正式上线ModelScope AIGC专区，支持在线免费的图像编辑。同时还支持在线界面GUI交互的模型训练，可以基于Flux.1 Kontext [dev] 底模训练LoRA模型。模型下载：[FLUX.1-Kontext-dev](https://modelscope.cn/models/black-forest-labs/FLUX.1-Kontext-dev)。
- 【开源】谷歌正式开源发布 Gemma 3n 端侧多模态模型，支持在手机、平板和笔记本电脑上本地运行，处理音频、文本、图片和视频多种数据类型。相较 此前的预览版，最新的 Gemma 3n 完整版进一步提升性能表现，支持在 2GB 内存的硬件上本地运行，重点提升了编码和推理方面的能力。本次开源提供50亿参数（E2B）和80亿参数（E4B）两种版本，实际内存占用分别相当于20亿和40亿模型。其采用MatFormer分层嵌套架构（类俄罗斯套娃设计），支持动态调节计算资源，结合Per Layer Embeddings（PLE）技术和MobileNet-v5视觉编码器，显著提升内存效率与视觉处理能力。模型强化多语言支持（140种文本语言、35种多模态理解）、数学运算、代码生成及复杂推理能力，适用于离线智能助手、实时多模态交互、本地化内容生成等场景，兼顾高性能与低功耗需求。模型下载：[gemma-3n-E2B-it](https://modelscope.cn/models/google/gemma-3n-E2B-it)。

### 6月26日
- 【闭源】阿里qwen-tts-2025-05-22，qwen-tts 模型的2025年5月22日快照版本。新增北京话、吴语和四川话三种音色。
- 【闭源】预览模型 gemini-2.5-pro-preview-05-06 和 gemini-2.5-pro-preview-03-25 现在将重定向至最新的稳定版本 gemini-2.5-pro。gemini-2.5-pro-exp-03-25 已被弃用。
- 【闭源】OpenAI推出两款全新的Deep Research API：o3-deep-research-2025-06-26和o4-mini-deep-research-2025-06-26，专为高阶分析和深度信息合成设计，可实现自动化的网页搜索、数据分析、代码执行等功能，支持多步骤研究，能生成结构化、带引用的报告。
- 【闭源】阿里通义千问推出 Qwen VLo，这是一个多模态统一理解与生成模型，引入从上到下、从左到右逐步清晰的生成过程，适用于需精细控制的长段落文字生成任务，详见[qwen-vlo](https://qwenlm.github.io/zh/blog/qwen-vlo)。未开源、未发布API，[体验地址](https://chat.qwen.ai)。
- 【开源】快手开源全新多模态大模型Keye-VL-8B-Preview，能把视频内容转化为解决方案，并且可智能选择思考模式，兼顾效率与创意。模型下载[Keye-VL-8B-Preview](https://huggingface.co/Kwai-Keye/Keye-VL-8B-Preview)。

### 6月25日
- 【开源】hunyuan-a13b 上线。适用场景：绝大部分场景，同时兼顾效果及推理性能。模型能力和特征：混元第一个混合推理模型，hunyuan-standard-256K 的升级版本，总参数80B，激活13B，默认是慢思考模式，支持通过参数或者指令进行快慢思考模式切换，慢快思考切换方式为 query 前加/ no_think；整体能力相对上一代全面提升，特别数学、科学、长文理解和 Agent 能力提升显著。模型结构：混元 MoE 结构。腾讯混元宣布开源首个混合推理 MoE 模型 Hunyuan-A13B，总参数 80B，激活参数仅 13B，效果比肩同等架构领先开源模型，且推理速度更快，性价比更高。模型下载[Hunyuan-A13B-Instruct](https://modelscope.cn/models/Tencent-Hunyuan/Hunyuan-A13B-Instruct)。
- 【闭源】百度ERNIE-4.5-Turbo-128K-Preview，模型能力全面提升，更好满足多轮长历史对话处理、长文档理解问答任务。此版本为本系列的最新版本。
- 【开源】Jina AI 正式开源发布 jina-embeddings-v4，一款全新的多模态向量模型，参数规模达到 38 亿，并首次实现了对文本与图像的同步处理。为了在各类检索任务中发挥极致性能，在模型内置了一套面向特定任务的 LoRA 适配器，专门强化了模型在处理查询-文档检索、语义匹配以及代码搜索等任务时的表现。在 MTEB、MMTEB、CoIR、LongEmbed、STS、Jina-VDR 及 ViDoRe 等多项基准测试中，jina-embeddings-v4  在多模态、多语言检索任务上均展现了顶尖性能。它尤其擅长解读富含视觉信息的内容，无论是表格、图表还是复杂的示意图，都能精准捕捉其深层语义。此外，模型还同时支持单向量和多向量表示，灵活满足各种场景需求。模型下载：[jina-embeddings-v4](https://modelscope.cn/models/jinaai/jina-embeddings-v4)。

### 6月24日
- 【闭源】谷歌发布 Imagen 4 Ultra 和标准预览模型。如需了解更多，请参见[图像生成页面](https://ai.google.dev/gemini-api/docs/image-generation)。

### 6月23日
- 【闭源】百度ERNIE-X1-Turbo-32K-Preview，相比ERNIE-X1-Turbo-32K，效果和性能更好。
- 【开源】月之暗面（MoonshotAI）开源发布了多模态模型 Kimi-VL-A3B-Thinking-2506，其凭借 28 亿激活参数、128K 上下文窗口及混合专家架构，展现出强大的视觉理解、推理及长文本、长视频处理能力。模型下载[Kimi-VL-A3B-Thinking-2506](https://modelscope.cn/models/moonshotai/Kimi-VL-A3B-Thinking-2506)。
<br><br>


## 6月16~6月22
### 6月22日
- 【闭源】MiniMax音乐模型music-1.5发布，新一代音乐生成模型，支持输入音乐灵感和歌词进行音乐生成。

### 6月19日
- 【闭源】hunyuan-t1-vision-20250619 上线。特性：混元最新版 t1-vision 多模态理解深度思考模型，支持多模态原生长思维链，相比上一代默认版本模型全面提升。
- 【闭源】hunyuan-turbos-vision-20250619 上线。特性：混元最新版 turbos-vision 视觉语言旗舰大模型，在图文理解相关的任务上，包括基于图片的实体识别、知识问答、文案创作、拍照解题等上面相比上一代默认版本模型全面提升。

### 6月18日
- 【闭源】智谱接入两个 Vidu 热门视频生成模型
  - Vidu Q1 聚焦高质量视频创作，固定输出 5 秒、24 帧、1080P 规格内容。凭借对清晰度的深度优化，画质质感大幅跃升；写实风格逼近真实场景，2D 动画画风精准保持，首尾帧转场更加丝滑，适用于影视、广告、动漫短剧等高要求创作场景。
  - Vidu 2 平衡速度、质量与成本，主攻图生视频、首尾帧功能，支持 4 秒时长下 720P分辨率输出。画面稳定可控适配电商等场景，首尾帧语义理解与多参考图一致性增强，是泛娱乐、互联网、动漫短剧、广告量产的高效工具。
- 【闭源】MiniMax视频模型MiniMax Hailuo 02正式发布，新一代视频生成模型，支持1080P高清，及10s更长视频。

### 6月17日
- 【闭源】谷歌发布 gemini-2.5-pro，这是最强大的模型的稳定版本，现已具备自适应思考功能。gemini-2.5-pro-preview-05-06 将于 2025 年 6 月 26 日重定向至 gemini-2.5-pro。
- 【闭源】谷歌发布 gemini-2.5-flash，这是首个稳定的 2.5 Flash 模型。gemini-2.5-flash-preview-04-17 将于 2025 年 7 月 15 日被弃用。
- 【闭源】谷歌发布 gemini-2.5-flash-lite-preview-06-17，这是一款低成本、高性能的 Gemini 2.5 模型。
- 【开源】Kimi-Dev-72B 是Kimi最新开源的一款大型编程语言模型，专为软件工程任务设计，通过大规模强化学习优化，能够在真实代码库中自动修复漏洞并通过测试验证，其在 SWE-bench Verified 数据集上以 60.4% 的性能刷新了开源模型的最高纪录。模型下载：[Kimi-Dev-72B](https://modelscope.cn/models/moonshotai/Kimi-Dev-72B)。

### 6月16日
- 【开源】MiniMax推理模型MiniMax-M1正式发布，全球领先：80K思维链 x 1M输入，效果比肩海外顶尖模型。MiniMax-M1 是MiniMax近期开源发布的全球首个开源的大规模混合架构推理模型，支持百万级上下文输入和最长 8 万 Token 的推理输出，总参数量 4560 亿，单次激活 459 亿 Tokens。它在长上下文理解、软件工程和工具使用等复杂任务中表现优异，性价比极高，并通过创新的强化学习算法 CISPO 实现高效训练。模型下载：[MiniMax-M1-80k](https://modelscope.cn/models/MiniMax/MiniMax-M1-80k)。
- 【开源】Lingshu系列，Lingshu-7B 是由阿里巴巴达摩院开源的一个专注于医疗领域的大型语言模型，推出7B、32B两个参数版本，在大多数医疗多模态/文本 QA 和报告生成任务中达到 SOTA 性能，能够为医学文本处理、临床辅助决策和医疗知识问答等任务提供高效支持。Lingshu-32B 在大多数多模态 QA 和报告生成任务中优于 GPT-4.1 和 Claude Sonnet 4。Lingshu 支持超过 12 种医学成像模式，包括 X 射线、CT 扫描、MRI、显微镜、超声波、组织病理学、皮肤镜检查、眼底、OCT、数字摄影、内窥镜检查和 PET。模型下载：[Lingshu-32B](https://modelscope.cn/models/DAMO_Academy/Lingshu-32B)。
<br><br>


## 6月9~6月15
### 6月15日
- 【闭源】字节跳动Doubao-Seed-1.6-thinking，在思考能力上进行了大幅强化， 对比Doubao-1.5-thinking-pro，在Coding、Math、 逻辑推理等基础能力上进一步提升。
- 【闭源】Doubao-Seed-1.6，全新多模态深度思考模型，同时支持thinking/non-thinking/auto三种思考模式， non-thinking模型对比Doubao-1.5-pro/250115大幅提升。
- 【闭源】Doubao-Seed-1.6-flash，极致推理速度的多模态深度思考模型， 同时支持文本和视觉理解，文本理解能力超过上一代lite，视觉理解比肩友商pro系列模型。

### 6月13日
- 【开源】Nanonets-OCR-s是一款强大的OCR模型，该模型基于Qwen2.5-VL-3B微调，9G显存可跑，能够通过智能内容识别和语义标记，将杂乱的文档转换为现代人工智能应用所需的干净、结构化且上下文丰富的 Markdown 格式。它的功能远超传统的文本提取，是目前图像转 Markdown 领域的SoTA模型。模型下载：[Nanonets-OCR-s](https://modelscope.cn/models/nanonets/Nanonets-OCR-s)。

### 6月11日
- 【开源】Magistral-Small-2506是基于Mistral Small 3.1（2503版本）的升级模型，通过融合Magistral Medium轨迹的监督微调（SFT）与强化学习（RL）训练，显著增强推理能力。这款高效的小型推理模型参数量达240亿，量化后可在单张RTX 4090显卡或32GB内存的MacBook本地部署。Magistral-Small-2506具备长推理链能力，支持英语、法语、中文等数十种语言，采用Apache 2.0开源许可（允许商业及非商业使用）。其128k上下文窗口实际建议设为40k，超过此范围性能可能下降。模型下载：[Magistral-Small-2506](https://modelscope.cn/models/mistralai/Magistral-Small-2506)。

### 6月10日
- 【闭源】OpenAI推出o3-pro，如同 o1-pro 一样，o3-pro 是最智能的模型 o3 的一个版本，专为长时间思考并提供最可靠的回答而设计。自 o1-pro 推出以来，用户一直青睐该模型在数学、科学和编程等领域的表现，而 o3-pro 在学术评估中也继续在这些领域表现出色。和 o3 一样，o3-pro 可以使用各种工具，使 ChatGPT 更加实用——它可以搜索网络、分析文件、对视觉输入进行推理、使用 Python、利用记忆个性化回答等等。

### 6月9日
- 【开源】MonkeyOCR是由华中科技大学联合金山办公推出的一款文档解析模型，具备高精度和强泛化能力。该模型支持多语言、多场景的文字检测与识别，适用于文档数字化、内容审核、信息提取等多种应用场合。与传统方法相比，MonkeyOCR在处理复杂文档时，平均性能提升5.1%，在公式和表格解析上分别提升15%、8.6%。模型下载：[MonkeyOCR](https://modelscope.cn/models/l1731396519/MonkeyOCR)。


<br><br>
## 6月2~6月8
### 6月7日
- 【闭源】OpenAI高级语音模式更新，为付费用户在 ChatGPT 中升级了高级语音模式，显著提升了语调和自然度，让对话更加流畅自然。

### 6月6日
- 【闭源】OpenAI o4-mini更新，撤销了不到一周前部署的 o4-mini 快照版本，该版本原本旨在延长模型回答的长度，但自动化监控工具发现内容标记有所增加。
- 【闭源】hunyuan-translation-lite模型版本更新。模型能力和特征：混元翻译专项模型，基于混元2B-Dense模型进行翻译能力专项优化，通过迭代高质量多语言SFT数据，强化多语种翻译能力。支持简体中文、繁体中文、粤语、印尼语、英语、日语、法语、葡萄牙语、西班牙语、土耳其语、俄语、阿拉伯语、韩语、意大利语、德语、越南语、马来语、印尼语等18种语言互译。模型结构：混元 Dense 结构。
- 【开源】dots.llm1 模型是小红书Hi lab团队（Humane Intelligence Lab）推出的一个大规模的 MoE 模型，从总共 142B 参数中激活了 14B 参数，性能与当前最先进的开源模型相当。 通过rednote-hilab研究团队精心设计和高效的数据处理流水线，dots.llm1 在没有合成数据的情况下，在高质量语料库上预训练后，达到了与 Qwen2.5-72B 相当的性能。为了进一步促进研究，研究团队开源了整个训练过程中的中间训练Checkpoint，并提供了对大型语言模型学习动态的宝贵见解。模型下载：[dots.llm1.inst](https://modelscope.cn/models/rednote-hilab/dots.llm1.inst)。

### 6月5日
- 【闭源】谷歌发布 gemini-2.5-pro-preview-06-05，这是最强大的模型的新版本，现已具备自适应思考功能。如需了解更多，请参见 Gemini 2.5 Pro 预览版和思考。gemini-2.5-pro-preview-05-06 将于 2025 年 6 月 26 日重定向至 gemini-2.5-pro。
- 【开源】面壁智能重磅推出MiniCPM 4.0 ——一个极致高效的端侧大模型，通过其 CPM.cu 自研推理框架，可实现220倍极致的速度提升，5 倍常规提速。本次在开源社区核心推出 8B 和 0.5B 两个参数规模的版本，均在同级别模型对比中实现了最佳性能。MiniCPM4系列通过系统性技术创新实现端侧大模型极致推理效率：采用InfLLM v2可训练稀疏注意力架构，在128K长文本处理中将词元关联计算量压缩至不足5%；结合BitCPM三值量化技术实现模型位宽90%压缩，配合FP8低精度计算与多词元预测策略显著降低训练成本；依托UltraClean数据清洗和UltraChat v2合成技术构建高质量多维训练集；推理端集成CPM.cu高效CUDA框架，融合稀疏注意力、模型量化与投机采样技术，并通过ArkInfer跨平台系统实现灵活部署。模型下载：[MiniCPM4-0.5B](https://modelscope.cn/models/OpenBMB/MiniCPM4-0.5B)。

### 6月4日
- 【闭源】腾讯混元hunyuan-turbos-20250604 上线。能力和特征：预训练底座升级，写作、阅读理解能力提升，较大幅度提升代码和理科能力，复杂指令遵循等持续提升。
- 【闭源】阿里发布text-embedding-v4，text-embedding-v4为text-embedding-v3的升级版模型，属于Qwen3-Embedding系列。相较于上一版模型，新版模型涵盖了更多自然语言以及多种编程语言，并新增2048及1536向量维度的选择。
- 【开源】阿里巴巴通义实验室开源Qwen3-Embedding系列模型, Qwen模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于Qwen3基础模型进行训练，充分继承了Qwen3在多语言文本理解能力方面的优势。基于Qwen3基础模型，Embedding模型和Reranker模型分别采用了双塔结构和单塔结构的设计。通过LoRA微调，最大限度地保留并继承了基础模型的文本理解能力。模型下载：[Qwen3-Embedding-8B](https://modelscope.cn/models/Qwen/Qwen3-Embedding-8B)。

### 6月3日
- 【闭源】阿里发布qvq-max-2025-05-15，视觉推理模型。较上一个版本，增强了在数学、编程、视觉分析、创作以及通用任务方面的能力。
- 【闭源】阿里发布qvq-plus-2025-05-15，视觉推理模型。支持视觉输入及思维链输出，继qvq-max模型后推出的plus版本，相较于qvq-max模型，qvq-plus系列模型推理速度更快，效果和成本更均衡。
- 【闭源】商汤发布最新版本日日新-语音大模型-语音合成（音色融合），日日新语音合成（音色融合）大模型基于文本到语音（Text-to-Speech, TTS）的同步语音合成功能，单次请求支持最大文本长度为 10000 字符，适用于短句生成、语音对话、在线社交等多种场景。








